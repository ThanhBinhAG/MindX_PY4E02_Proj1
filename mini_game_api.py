#!/usr/bin/env python3
"""
Mini Game Analytics Dashboard API
---------------------------------
Backend Flask ƒë·ªçc d·ªØ li·ªáu Steam CSV, x·ª≠ l√Ω nh·∫π b·∫±ng pandas,
cung c·∫•p c√°c endpoint ph√¢n t√≠ch v√† tr·ª±c quan h√≥a, ƒë·ªìng th·ªùi
serve file index.html trong th∆∞ m·ª•c frontend/ ƒë·ªÉ demo.
"""

from flask import Flask, jsonify, request, send_file, send_from_directory, abort
from flask_cors import CORS
import pandas as pd
import numpy as np
import io
import os
import re  # <-- TH√äM D√íNG N√ÄY
from datetime import datetime

# ===================== CONFIG =====================
CSV_PATH = os.environ.get("STEAM_CSV", "mini-game-dashboard/data/steam.csv")
PARQUET_PATH = None  # kh√¥ng d√πng parquet
DEFAULT_DATE_COL = "release_date"
PORT = int(os.environ.get("PORT", 5000))
# ==================================================

app = Flask(__name__)
CORS(app)

# ----------------- Utilities -----------------
def load_df():
    """Load CSV (ho·∫∑c parquet n·∫øu c√≥)."""
    if PARQUET_PATH and os.path.exists(PARQUET_PATH):
        df = pd.read_parquet(PARQUET_PATH)
        return df
    if not os.path.exists(CSV_PATH):
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y dataset t·∫°i {CSV_PATH}")
    df = pd.read_csv(CSV_PATH, low_memory=False)
    return light_clean(df)

def light_clean(df):
    """X·ª≠ l√Ω nh·∫π d·ªØ li·ªáu: ng√†y ph√°t h√†nh, gi√°, owners, t·ªâ l·ªá ƒë√°nh gi√°,..."""
    # Ng√†y ph√°t h√†nh
    if DEFAULT_DATE_COL in df.columns:
        df[DEFAULT_DATE_COL] = pd.to_datetime(df[DEFAULT_DATE_COL], errors='coerce')
    else:
        for c in df.columns:
            if 'release' in c.lower():
                df[DEFAULT_DATE_COL] = pd.to_datetime(df[c], errors='coerce')
                break
        if DEFAULT_DATE_COL not in df.columns:
            df[DEFAULT_DATE_COL] = pd.NaT
    df["release_year"] = df[DEFAULT_DATE_COL].dt.year.fillna(0).astype(int)

    # Gi√°
    if "price" in df.columns:
        df["price"] = pd.to_numeric(df["price"], errors="coerce").fillna(0.0)
    else:
        df["price"] = 0.0

    # Positive / negative
    pos = next((c for c in df.columns if "positive" in c.lower()), None)
    neg = next((c for c in df.columns if "negative" in c.lower()), None)
    df["positive"] = pd.to_numeric(df[pos], errors="coerce").fillna(0) if pos else 0
    df["negative"] = pd.to_numeric(df[neg], errors="coerce").fillna(0) if neg else 0
    df["positive_rate"] = df.apply(
        lambda r: r["positive"] / (r["positive"] + r["negative"])
        if (r["positive"] + r["negative"]) > 0
        else 0,
        axis=1,
    )

    # Owners [S·ª¨ D·ª§NG H√ÄM M·ªöI]
    owner_col = next((c for c in df.columns if "owner" in c.lower()), None)
    if owner_col:
        # √Åp d·ª•ng h√†m parse_owner_range m·ªõi
        df["owners"] = df[owner_col].apply(parse_owner_range).fillna(0).astype(int)
    else:
        df["owners"] = 0

    # Popularity
    df["popularity"] = np.log1p(df["owners"]) * (df["positive_rate"] + 0.01)

    # Genres
    if "genres" in df.columns:
        df["genres"] = df["genres"].fillna("").astype(str)
    else:
        df["genres"] = ""

    # Region fallback
    if "region" not in df.columns:
        df["region"] = "Global"

    # Avg playtime
    play_col = next((c for c in df.columns if "playtime" in c.lower()), None)
    if play_col:
        df["avg_playtime"] = pd.to_numeric(df[play_col], errors="coerce").fillna(0)
    else:
        df["avg_playtime"] = 0

    # Ensure name & appid
    if "name" not in df.columns:
        df["name"] = df.index.astype(str)
    if "appid" not in df.columns:
        df["appid"] = range(1, len(df) + 1)

    return df


def apply_filters(df, params):
    """L·ªçc d·ªØ li·ªáu theo tham s·ªë URL."""
    d = df
    start = params.get("start") or params.get("start_date")
    end = params.get("end") or params.get("end_date")
    genre = params.get("genre")
    region = params.get("region")
    publisher = params.get("publisher")
    q = params.get("q")
    min_price = params.get("min_price")
    max_price = params.get("max_price")

    if start:
        d = d[d[DEFAULT_DATE_COL] >= pd.to_datetime(start, errors="coerce")]
    if end:
        d = d[d[DEFAULT_DATE_COL] <= pd.to_datetime(end, errors="coerce")]
    if genre:
        d = d[d["genres"].str.contains(genre, case=False, na=False)]
    if region:
        d = d[d["region"].str.contains(region, case=False, na=False)]
    if publisher and "publisher" in d.columns:
        d = d[d["publisher"].astype(str).str.contains(publisher, case=False, na=False)]
    if q:
        d = d[d["name"].astype(str).str.contains(q, case=False, na=False)]
    if min_price:
        d = d[d["price"] >= float(min_price)]
    if max_price:
        d = d[d["price"] <= float(max_price)]

    return d


# [M√É ƒê√É S·ª¨A] H√†m tr·ª£ gi√∫p ƒë·ªÉ x·ª≠ l√Ω kho·∫£ng gi√° tr·ªã "owners"
def parse_owner_range(owner_str):
    """
    Chuy·ªÉn ƒë·ªïi chu·ªói "100,000 - 200,000" ho·∫∑c "100,000" th√†nh s·ªë.
    S·ª≠ d·ª•ng regex ƒë·ªÉ t√¨m t·∫•t c·∫£ c√°c s·ªë trong chu·ªói, b·∫•t k·ªÉ ƒë·ªãnh d·∫°ng.
    """
    try:
        # 1. L√†m s·∫°ch chu·ªói: lo·∫°i b·ªè d·∫•u ph·∫©y
        cleaned_str = str(owner_str).replace(',', '')
        
        # 2. T√¨m t·∫•t c·∫£ c√°c chu·ªói s·ªë (v√≠ d·ª•: "100000", "200000")
        numbers = re.findall(r'\d+', cleaned_str)
        
        if len(numbers) == 0:
            # Kh√¥ng t√¨m th·∫•y s·ªë (v√≠ d·ª•: "N/A", "nan")
            return 0
        elif len(numbers) == 1:
            # Ch·ªâ c√≥ 1 s·ªë (v√≠ d·ª•: "20000")
            return int(numbers[0])
        elif len(numbers) >= 2:
            # C√≥ 2 s·ªë tr·ªü l√™n (v√≠ d·ª•: "100000 - 200000")
            # Ch√∫ng ta ch·ªâ l·∫•y 2 s·ªë ƒë·∫ßu ti√™n
            low = int(numbers[0])
            high = int(numbers[1])
            # L·∫•y trung b√¨nh c·ªông
            return (low + high) / 2
    except Exception:
        # B·∫•t k·ª≥ l·ªói n√†o kh√°c
        return 0

# ----------------- API Endpoints -----------------
@app.route("/api/stats/summary")
def summary():
    """T·ªïng quan ch·ªâ s·ªë (KPI)."""
    df = load_df()
    df = apply_filters(df, request.args)
    total_games = len(df)
    avg_price = round(df["price"].mean(), 2)
    avg_playtime = round(df["avg_playtime"].mean(), 2)
    total_owners = int(df["owners"].sum())
    top_genre = (
        df["genres"].str.split(";").explode().str.strip().value_counts().idxmax()
        if not df.empty and not df["genres"].str.strip().eq("").all()
        else "N/A" # Th√™m ki·ªÉm tra ƒë·ªÉ tr√°nh l·ªói n·∫øu kh√¥ng c√≥ genre
    )
    return jsonify(
        {
            "total_games": total_games,
            "avg_price": avg_price,
            "avg_playtime": avg_playtime,
            "total_owners": total_owners,
            "top_genre": top_genre,
        }
    )


@app.route("/api/top")
def top_games():
    """Top N theo ch·ªâ s·ªë."""
    df = load_df()
    df = apply_filters(df, request.args)
    metric = request.args.get("metric", "popularity")
    n = int(request.args.get("n", 10))
    if metric not in df.columns:
        return jsonify({"error": f"Metric '{metric}' kh√¥ng t·ªìn t·∫°i."}), 400
    top = df.sort_values(metric, ascending=False).head(n)
    return jsonify(top[["appid", "name", metric, "price", "release_year"]].to_dict(orient="records"))


@app.route("/api/series")
def series():
    """D·ªØ li·ªáu time-series theo nƒÉm."""
    df = load_df()
    df = apply_filters(df, request.args)
    
    # L·ªçc b·ªè nh·ªØng nƒÉm kh√¥ng h·ª£p l·ªá (v√≠ d·ª•: nƒÉm 0)
    df_valid_year = df[df["release_year"] > 1990] # Gi·∫£ s·ª≠ ch·ªâ l·∫•y game sau 1990
    
    metric = request.args.get("metric", "count")
    group = df_valid_year.groupby("release_year") # Nh√≥m theo 'release_year' ƒë√£ x·ª≠ l√Ω
    
    if metric == "avg_price":
        res = group["price"].mean()
    else:
        res = group.size()
        
    out = {str(int(k)): float(v) for k, v in res.sort_index().items()}
    return jsonify(out)


@app.route("/api/aggregate")
def aggregate():
    """Ph√¢n b·ªë theo genre / region / publisher."""
    df = load_df()
    df = apply_filters(df, request.args)
    by = request.args.get("by", "genre")
    if by == "region":
        s = df["region"].fillna("Unknown").value_counts().to_dict()
    elif by == "publisher" and "publisher" in df.columns:
        s = df["publisher"].fillna("Unknown").value_counts().to_dict()
    else:
        # T√°ch 'genres', lo·∫°i b·ªè kho·∫£ng tr·∫Øng, lo·∫°i b·ªè gi√° tr·ªã r·ªóng v√† ƒë·∫øm
        s = df["genres"].str.split(";").explode().str.strip()
        s = s[s != ''].value_counts().to_dict()
    return jsonify(s)


@app.route("/api/export")
def export_csv():
    """Xu·∫•t d·ªØ li·ªáu l·ªçc hi·ªán t·∫°i ra CSV."""
    df = load_df()
    df = apply_filters(df, request.args)
    buf = io.StringIO()
    df.to_csv(buf, index=False)
    buf.seek(0)
    return send_file(
        io.BytesIO(buf.getvalue().encode("utf-8")),
        mimetype="text/csv",
        as_attachment=True,
        download_name="export_filtered.csv",
    )


@app.route("/health")
def health():
    return jsonify({"status": "ok", "time": datetime.utcnow().isoformat() + "Z"})


# ----------------- Serve frontend -----------------
@app.route("/")
def serve_frontend():
    """Tr·∫£ v·ªÅ file index.html n·∫øu c√≥, ho·∫∑c h∆∞·ªõng d·∫´n API."""
    base = os.path.join(os.path.dirname(__file__), "frontend")
    index_path = os.path.join(base, "index.html")
    if os.path.exists(index_path):
        return send_from_directory(base, "index.html")
    return jsonify(
        {
            "message": "Mini Game API ƒëang ch·∫°y!",
            "hint": "Th√™m file frontend/index.html ƒë·ªÉ hi·ªÉn th·ªã dashboard.",
            "endpoints": ["/api/stats/summary", "/api/top", "/api/series", "/api/aggregate"],
        }
    )


# ----------------- Run -----------------
if __name__ == "__main__":
    csv_status = "‚úÖ found" if os.path.exists(CSV_PATH) else "‚ùå missing"
    print("=" * 60)
    print("üöÄ Starting Mini Game Analytics API")
    print(f"üì¶ Dataset: {CSV_PATH} ‚Üí {csv_status}")
    print(f"üåê Running on: http://127.0.0.1:{PORT}")
    print("=" * 60)
    app.run(host="0.0.0.0", port=PORT, debug=True)